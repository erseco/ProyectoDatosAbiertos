\chapter{Introducción}

\section{Descripción del problema}

Este {\sf Trabajo Fin de Máster} aborda el problema de la obtención de información de los datos contenido en un portal de datos abiertos mediante peticiones a un interfaz en forma de consultas, esto nos permitirá obtener conclusiones sobre la información subyacente en los datos.

\bigskip
Actualmente el portal de datos abiertos de la {\sf Universidad de Granada}\footnote{\url{http://opendata.ugr.es/}} tiene 40 conjuntos de datos con 340 tablas de datos sobre diferentes aspectos de la propia Universidad: matrículas, demanda académica, información salarial, empleo de egresados...

\bigskip
En cumplimiento de la legislación vigente sobre reutilización de la información del \textbf{Sector Público (Ley 37/2007 de 16 de noviembre\footnote{\url{https://sedempr.gob.es/sites/default/files/fileupload/A47160-47165.pdf}} y Real Decreto 1495/2011 de 24 de octubre\footnote{\url{https://sedempr.gob.es/sites/default/files/fileupload/BOE-A-2011-17560\_0.pdf}})} podemos encontrar un gran número de portales abiertos tanto a nivel regional como nacional; sin embargo, no en todos podemos encontrar la misma facilidad para trabajar con los propios datos.

\bigskip
% Nada de la universidad. Ha sido en hackatones.
En el caso particular de la {\sf Universidad de Granada} se ha venido trabajando con mucho interés en los datos relacionados con las matriculaciones para intentar explicar por ejemplo la tendencia en la elección de titulaciones de determinadas ramas de conocimiento en función del sexo del estudiante. Es por eso que este tipo de datos serán los primeros en ser adaptados para ser procesados mediante este sistema, pudiendo además extenderse a los mismos datos procedentes de otras universidades para tener una visión más global; y finalmente ampliando a otros conjuntos de datos precisos. 

\newpage
Para que podamos trabajar con los datos de esa forma, es necesario primero que dichos datos sean \textit{entendibles} por una máquina de forma que intuitivamente representen la realidad del mundo físico, reproduciendo las propiedades que puede tener un entidad y las acciones que puede llevar a cabo; para ello es necesario disponer de información adicional que describan el contenido, el significado y la relación entre los datos. Esto es lo que se conoce como \textbf{Web Semántica}.

\section{Web semántica}
La idea original sobre la Web Semántica fue propuesta por {\sf Tim Berners-Lee} en el año 2001 partiendo de la base de que {\sf la Web actual} estaba demasiado orientada a que sus contenidos fueran leídos por humanos, ya que sus contenidos y documentos tenían un diseño que priorizaba su aspecto sobre su significado. Precisamente esto es lo que se quiere conseguir con {\sf la Web semántica}, darle significado a los datos de forma que no dependan de la apreciación que les pueda dar un lector humano, si no que también puedan ser fácilmente interpretados por las máquinas. Para que esto sea posible, es necesario proporcionar una infraestructura que permita a las máquinas acceder a una estructura común de datos, consiguiendo así que todos los datos queden integrados y enlazados en una especie de base de datos mundial que sea la agregación de innumerables fuentes de datos, pero que gracias a esa estructura común permita una fácil interoperatividad entre distintos sistemas, lo que también se conseguirá gracias al establecimiento de una serie de reglas que permitirán que las máquinas creen hagan uso de unos mecanismo de inferencia que les permitan interpretar los datos que están procesando, 

\bigskip
Para definir esta estructura común de datos se utiliza el modelo de datos {\sf RDF (Resource Description Framework)}, este modelo nos provee de un prototipo estándar para el intercambio de información entre diferentes fuentes de forma que no pierdan su significa y sea posible su interpretación por las máquinas. 

\bigskip En {\sf RDF} la información descriptiva sobre los recursos se construyo en forma de expresiones sujeto-predicado-objeto, lo que se conoce como un \textbf{triple RDF}. Por ejemplo, si tomamos el triple RDF ``Titulación - perteneceA - RamaConocimiento" un caso particular sería ``Informática - perteneceA - IngenieríaArquitectura". Además, para que estos datos se puede referenciar inequívocamente a través de la Web cada elemento tendrá un {\sf URI (Universal Resource Identifier)}.

\bigskip

Otro elemento fundamental a tener en cuenta a la hora de dotar de significa a los datos son las ontologías. Una ontología nos permite hacer una definición formal de los conceptos del dominio de interés con el que estamos tratando, indicando cuáles son sus tipos, propiedades y relaciones de forma que podamos detallar el estado completo de lo que estamos queriendo modelar.

\bigskip
Una vez que ya tenemos la estructura de datos creada, simplemente nos quedará establecer algún mecanismo que nos permita realizar consultas sobre esa información. Para esto la {\sf W3C (World Wide Consortium)} recomienda oficialmente hacer uso de {\sf SPARQL (SPARQL Protocol and RDF Query Language)}. {\sf SPARQL} es una lenguaje estandarizado para la consulta de grafos {\sf RDF} de distintas fuentes de datos que permite hacer búsquedas sobre los recursos utilizando consultas que se asemejan a las típicamente usadas sobre bases de datos relacionales.

\bigskip

Un aspecto que falta por comentar y que es muy importante es el concepto de \textbf{dato enlazado}, más generalmente referido con su traducción en ingles \textbf{linked data}. La idea detrás de los datos enlazados es que además de publicar la información referente a los datos, también se vinculen a otros datos relacionados similares de forma que cuando una máquina procese la información semántica de dichos datos, automáticamente también pueda llegar a información relacionada, pero que no está incluida en la publicación de los datos originales en los datos originales. Esto también se consigue gracias a la existencia de las ontologías, ya que la posibilidad de estudiar el dominio a tratar hace que los datos puedan ser reutilizados e integrados en otros sistemas permitiendo así una interoperabilidad de los mismos.

\bigskip
Para poder usar datos enlazados es imprescindible hacer dos cosas: que nuestros recursos tengan un {\sf URI} que les permita ser identificados de forma inequívoca en {\sf la Web} y, además, que nuestros recursos incluyan enlaces a otros {URI} relacionadas con los datos contenidos en nuestros recursos. Uno de los conjuntos de datos más se suelen usar para enlazar datos es {\sf DBpedia\footnote{\url{http://wiki.dbpedia.org/}}}, un proyecto para extraer datos de {\sf Wikipedia\footnote{\url{https://www.wikipedia.org/}}} de forma que se pueda obtener una versión de la misma transformada en web semántica.

\newpage
\section{La web semántica en otras universidades}

A nivel nacional, aunque si bien es cierto que muchas instituciones públicas con las normativas antes mencionadas se apresuraron a crear sus propios portales de transparencia y/o catálogos de datos abiertos, hoy en día son pocas las universidades que mantienen los datos actualizados y los servicios endpoint {\sf SPARQL} funcionando (los que dispusieran de uno). Parándonos a buscar entre las universidades de mayor relevancia, podemos encontrar con casos como los de la {\sf Universitat Pompeu Fabra} \footnote{\url{https://data.upf.edu/}} o la {\sf Universidad Pablo de Olavide} \footnote{\url{https://datos.upo.gob.es/}}, ambas con datos sin actualizar desde hace varios años y un endpoint de {\sf SPARQL} inoperativo.

\bigskip
Aunque también hay que decidir que la adaptación de este tipo de tecnologías por las universidades en general ha sido pobre, internacionalmente si podemos encontrar auténticos referentes como es la {\sf University of Southampton} \footnote{\url{http://data.southampton.ac.uk/}}, donde podemos encontrar decenas de conjuntos de datos actualizados, además de proveer de un endpoint {\sf SPARQL} totalmente funcional.